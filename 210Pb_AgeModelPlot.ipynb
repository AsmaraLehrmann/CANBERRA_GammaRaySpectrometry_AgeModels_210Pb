{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d518608",
   "metadata": {},
   "source": [
    "# Welcome to the 210Pb age model script!\n",
    "\n",
    "### <div style=\"text-align: right\"> Last modified by A.A. Lehrmann 25 June 2025 </div>\n",
    "\n",
    "\n",
    "### The script below will extract radioisotope data from Canberra PDFs, run the age model (from the Wellner Lab Group excel model (Appleby, 2001; Boldt et al., 2013), and plot the age model\n",
    "\n",
    "### Important instructions before you begin:\n",
    "\n",
    "    1. NEVER edit raw data. Do not delete Canberra PDFs. Do not remove sediment weights from original lab notebook excel sheet.\n",
    "\n",
    "    2. Make an /CORE_AgeModelOutput/ folder to put all of your script's outputs\n",
    "\n",
    "    3. When copying folder paths, make sure to remove quotation marks\n",
    "\n",
    "    4. Always add the extension .csv to your output files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a513b53",
   "metadata": {},
   "source": [
    "## First, extract radioisotope data from Canberra PDFs\n",
    "Run cell (press triangle that says run) and follow instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937424bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process pt_src files\n",
    "def process_ptsrc_pdf(file_path, filename):\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        if len(reader.pages) < 3:\n",
    "            print(f\"PDF file '{filename}' has less than 3 pages. Skipping.\")\n",
    "            return None\n",
    "        page = reader.pages[2]\n",
    "        text = page.extract_text()\n",
    "        lines = text.split('\\n')\n",
    "        for line in lines:\n",
    "            if 'Pb-210' in line:\n",
    "                ptsrc_pb210, PtSrc_Pb210error = line.split()[-2:]\n",
    "                return {\n",
    "                    'File': filename,\n",
    "                    'Pb-210': float(ptsrc_pb210),\n",
    "                    'Pb-210 error': float(PtSrc_Pb210error)\n",
    "                }\n",
    "        print(f\"Pb-210 not found in '{filename}'. Skipping.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF file '{filename}': {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0995561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process regular files\n",
    "def process_regular_pdf(file_path, filename):\n",
    "    pb210 = pb210error = Bi214 = Bi214error = Pb214 = Pb214error = None\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        if len(reader.pages) < 3:\n",
    "            print(f\"PDF file '{filename}' has less than 3 pages. Skipping.\")\n",
    "            return None\n",
    "        page = reader.pages[2]\n",
    "        text = page.extract_text()\n",
    "        lines = text.split('\\n')\n",
    "        for line in lines:\n",
    "            if 'Pb-210' in line:\n",
    "                pb210, pb210error = line.split()[-2:]\n",
    "            elif 'Bi-214' in line:\n",
    "                Bi214, Bi214error = line.split()[-2:]\n",
    "            elif 'Pb-214' in line:\n",
    "                Pb214, Pb214error = line.split()[-2:]\n",
    "        if pb210 is None or pb210error is None:\n",
    "            print(f\"Pb-210 not found in '{filename}'. Skipping.\")\n",
    "            return None\n",
    "        if Bi214 is None or Bi214error is None:\n",
    "            print(f\"Bi-214 not found in '{filename}'. Skipping.\")\n",
    "            return None\n",
    "        if Pb214 is None or Pb214error is None:\n",
    "            print(f\"Pb-214 not found in '{filename}'. Skipping.\")\n",
    "            return None\n",
    "        return {\n",
    "            'File': filename,\n",
    "            'Pb-210': float(pb210),\n",
    "            'Pb-210 error': float(pb210error),\n",
    "            'Bi-214': float(Bi214),\n",
    "            'Bi-214 error': float(Bi214error),\n",
    "            'Pb-214': float(Pb214),\n",
    "            'Pb-214 error': float(Pb214error)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF file '{filename}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cef998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define PDF processing\n",
    "def process_pdf_file(file_path, filename):\n",
    "    if filename.startswith(\"PtSrc_\"):\n",
    "        return process_ptsrc_pdf(file_path, filename)\n",
    "    else:\n",
    "        return process_regular_pdf(file_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43489c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract PDF data from folder\n",
    "def extract_pdf_data(folder_path):\n",
    "    combined_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check for PDF extension (case-insensitive)\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            data = process_pdf_file(file_path, filename)\n",
    "            if data is not None:\n",
    "                combined_data.append(data)\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort and process PDFs\n",
    "def sort_pdf_data(combined_data, parse_numbers=False):\n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "    \n",
    "    def extract_numeric_suffix(file_name):\n",
    "        try:\n",
    "            parts = file_name.split('_')[-1].split('.')[0]\n",
    "            return int(parts)\n",
    "        except ValueError:\n",
    "            return float('nan')\n",
    "    \n",
    "    combined_df['File_order'] = combined_df['File'].apply(extract_numeric_suffix)\n",
    "    combined_df = combined_df.sort_values(by='File_order').drop(columns=['File_order'])\n",
    "    \n",
    "    if parse_numbers:\n",
    "        for col in ['Pb-210', 'Bi-214', 'Pb-214']:\n",
    "            if col in combined_df.columns:\n",
    "                combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "def extract_pdf_values(folder_path, output_csv_path, parse_numbers=False):\n",
    "    combined_data = extract_pdf_data(folder_path)\n",
    "    combined_df = sort_pdf_data(combined_data, parse_numbers)\n",
    "    combined_df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a50848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User inputs\n",
    "folder_path = input(\"Enter the folder path of Canberra PDFs: \")\n",
    "output_csv_path = input(\"Enter the output CSV file path (e.g. CORE_CanberraData_DATE.csv): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute functions\n",
    "extract_pdf_values(folder_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7568417",
   "metadata": {},
   "source": [
    "### Make note of which samples are missing data! This will be important when we plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ac233",
   "metadata": {},
   "source": [
    "# Open the output .csv file\n",
    "\n",
    "Check to make sure all radioisotope data translated correctly. \n",
    "\n",
    "# Create two new columns\n",
    "- ptsrc_pb210\n",
    "- ptsrc_pb210 error\n",
    "\n",
    "# Move Point Source Lead 210 data to ptsrc_pb210 and uncertainty to ptsrc_pb210 error of associated samples\n",
    "\n",
    "# CHECK the following\n",
    "\n",
    "Radioisotope data should have the following headings\n",
    "\n",
    " ### | File    | Pb-210   | Pb-210 error    | Bi-214  | Bi-214 error   | Pb-214    |Pb-214 error |  ptsrc_pb210    | ptsrc_pb210 error  | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f82fd",
   "metadata": {},
   "source": [
    "# Create a new .csv file from lab notebook for the sample weight data\n",
    "\n",
    "Sample weights should have the following headings: \n",
    "\n",
    "### | Core    | Top of interval (cm)   | Center point of interval    |Base of interval (cm)  | sediment weight (g)    | \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391b5ac2",
   "metadata": {},
   "source": [
    "Run cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776436fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Prompt user for file paths and output file name\n",
    "csv1_path = input(\"Enter the path to the sample weight CSV file (e.g., /path/weights.csv): \")\n",
    "csv2_path = input(\"Enter the path to the Canberra data CSV file (e.g., /path/canberra.csv): \")\n",
    "output_file_name = input(\"Enter the path for the output CSV file (e.g., CORE_AgeModel_DATE.csv): \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e60839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and merge data\n",
    "# Load the CSV files\n",
    "csv1 = pd.read_csv(csv1_path)\n",
    "csv2 = pd.read_csv(csv2_path)\n",
    "\n",
    "# Extract 'Center point of interval' from csv2 based on the median of the last digits in 'File'\n",
    "csv2['Center point of interval'] = csv2['File'].apply(\n",
    "    lambda x: np.median([int(num) for num in re.findall(r'\\d+', x.split('_')[-1])])\n",
    ")\n",
    "\n",
    "# Merge CSV files on 'Center point of interval'\n",
    "data = pd.merge(csv1, csv2, on='Center point of interval', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the user for the year of core\n",
    "year_of_core = int(input(\"Enter the year of core (e.g., 2023): \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate activity and correction factors\n",
    "data['Pb-210 activity Uncertainty (Bq-g)'] = data['Pb-210 error']/data['sediment weight (g)']\n",
    "data['Pb-210 activity (Bq/g)'] = data['Pb-210'] / data['sediment weight (g)']\n",
    "data['Pb-210 correction factor'] = data['ptsrc_pb210'] / 151031.56\n",
    "data['Self absorb. Corrected Pb-210 activity (Bq/g)'] = (\n",
    "    data['Pb-210 activity (Bq/g)'] / data['Pb-210 correction factor']\n",
    ")\n",
    "data['Bi-214 activity (Bq/g)'] = data['Bi-214'] / data['sediment weight (g)']\n",
    "data['Pb-214 activity (Bq/g)'] = data['Pb-214'] / data['sediment weight (g)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf63be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averaged supported activity of Bi-214 and Pb-214 (Bq/g)\n",
    "data['Averaged supported activity of Bi-214 and Pb-214 (Bq/g)'] = (\n",
    "    data['Bi-214 activity (Bq/g)'] + data['Pb-214 activity (Bq/g)']\n",
    ") / 2\n",
    "\n",
    "# Calculate background activity uncertainty (Bq/g)\n",
    "data['Background activity uncertainty (Bq/g)'] = (\n",
    "    (data['Bi-214 error'] + data['Pb-214 error']) / 2\n",
    ") / data['sediment weight (g)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01701f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Excess Pb-210 (Bq/g)\n",
    "data['Excess Pb-210 (Bq/g)'] = (\n",
    "    data['Self absorb. Corrected Pb-210 activity (Bq/g)'] -\n",
    "    data['Averaged supported activity of Bi-214 and Pb-214 (Bq/g)']\n",
    ")\n",
    "\n",
    "# Determine surface activity (first interval value)\n",
    "data['Surface activity'] = data['Excess Pb-210 (Bq/g)'].iloc[0]\n",
    "\n",
    "# Calculate Age bp using the natural logarithm\n",
    "data['Age bp'] = (1 / 0.03114) * np.log(data['Surface activity'] / data['Excess Pb-210 (Bq/g)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 'calendar years pre year of core'\n",
    "data['calendar years pre year of core'] = year_of_core - data['Age bp']\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "data.to_csv(output_file_name, index=False)\n",
    "\n",
    "print(f\"Calculations completed, data exported to '{output_file_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d497d",
   "metadata": {},
   "source": [
    "# Check the output data. Make sure data isnt *fishy*\n",
    "Look at the column labeled 'Age'. Are the ages within the realm of possibility? If not, ask Asmara for help!\n",
    "\n",
    "# Now plot it!\n",
    "Run cell below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80727060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ask for the age model file to be plotted (CSV format)\n",
    "age_model_file = input(\"Enter the full path to the age model file to plot (e.g., /path/to/age_model.csv): \")\n",
    "data = pd.read_csv(age_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3938c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the core name for the plot title\n",
    "core_name = input(\"Enter the core name for the title: \")\n",
    "\n",
    "# Ask for depths to label \"calendar years pre year of core\"\n",
    "depths_to_label_input = input(\"Enter the depths (comma-separated) where 'calendar years pre year of core' should be labeled (or type 'all' to label all intervals): \")\n",
    "\n",
    "if depths_to_label_input.lower() == 'all':\n",
    "    depths_to_label = data['Center point of interval'].tolist()  # Label all intervals\n",
    "else:\n",
    "    depths_to_label = [float(depth.strip()) for depth in depths_to_label_input.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ccf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask if any intervals have undetectable radioisotope amounts\n",
    "missing_data_input = input(\"Are there any intervals with undetectable amounts of radioisotopes? (yes/no): \").strip().lower()\n",
    "\n",
    "if missing_data_input == 'yes':\n",
    "    missing_depths_input = input(\"Enter the depths (comma-separated) with undetectable radioisotopes: \")\n",
    "    missing_depths = [float(depth.strip()) for depth in missing_depths_input.split(\",\")]\n",
    "else:\n",
    "    missing_depths = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a581232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for the data series and error bars\n",
    "excess_pb210_color = 'black'\n",
    "excess_pb210_error_color = mcolors.to_rgba(excess_pb210_color, alpha=0.3)\n",
    "supported_activity_color = 'grey'\n",
    "supported_activity_error_color = mcolors.to_rgba(supported_activity_color, alpha=0.3)\n",
    "\n",
    "# Ask for the folder to save the plot PDF and create a filename\n",
    "save_location = input(\"Enter the full path where you want to save the plot PDF (e.g., /path/to/your/directory): \")\n",
    "plot_filename = f\"{core_name}_Age_Model.pdf\"\n",
    "save_path = save_location.rstrip('/') + \"/\" + plot_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 5))\n",
    "plt.errorbar(\n",
    "    data['Pb-210 activity (Bq/g)'], data['Center point of interval'], \n",
    "    xerr=data['Pb-210 activity Uncertainty (Bq-g)'], fmt='-', color=excess_pb210_color, \n",
    "    label='Pb-210 activity (Bq/unit)', capsize=5, linewidth=1, \n",
    "    ecolor=excess_pb210_error_color\n",
    ")\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.01, 10)\n",
    "# Highlight intervals with missing radioisotopes using brown spans\n",
    "for y in missing_depths:\n",
    "    plt.axhspan(y - 0.5, y + 0.5, alpha=0.5, color='brown', \n",
    "                label='Undetectable radioisotope' if y == missing_depths[0] else None)\n",
    "\n",
    "plt.title(f\"{core_name} 210 Pb Uncorrected Activity\", fontsize=18)\n",
    "plt.xlabel(\"Bq/g\", fontsize=14)\n",
    "plt.ylabel(\"Depth (cm)\", fontsize=14)\n",
    "plt.gca().invert_yaxis()  # Show depth from surface (invert y-axis)\n",
    "plt.grid(True, which='both', linestyle='-', linewidth=0.5, color='lightgray')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path, format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae8d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.figure(figsize=(5, 10))\n",
    "\n",
    "# Calculate vertical errors from top/base to center of interval\n",
    "depth_errors = np.array([\n",
    "    [center - top, base - center]\n",
    "    for top, center, base in zip(\n",
    "        data['top of interval (cm)'],\n",
    "        data['Center point of interval'],\n",
    "        data['Base of interval (cm)']\n",
    "    )\n",
    "]).T  # shape (2, N)\n",
    "\n",
    "# Calculate symmetric vertical errors\n",
    "yerr = np.abs(data['Center point of interval'] - data['top of interval (cm)'])\n",
    "\n",
    "# Calculate symmetric horizontal errors\n",
    "xerr = data['Pb-210 activity Uncertainty (Bq-g)']\n",
    "\n",
    "# Draw connecting line for Excess Pb-210 data points\n",
    "plt.plot(\n",
    "    data['Excess Pb-210 (Bq/g)'], data['Center point of interval'],\n",
    "    color=excess_pb210_color, linewidth=1, zorder=1\n",
    ")\n",
    "\n",
    "# Draw error boxes for Excess Pb-210\n",
    "for i in range(len(data)):\n",
    "    x = data['Excess Pb-210 (Bq/g)'].iloc[i]\n",
    "    y = data['Center point of interval'].iloc[i]\n",
    "    width = xerr.iloc[i] * 2\n",
    "    height = yerr.iloc[i] * 2\n",
    "    rect = patches.Rectangle(\n",
    "        (x - xerr.iloc[i], y - yerr.iloc[i]), width, height,\n",
    "        linewidth=0.5, edgecolor='grey', facecolor='none'\n",
    "    )\n",
    "    plt.gca().add_patch(rect)\n",
    "\n",
    "# Plot background activity with horizontal error bars only\n",
    "plt.errorbar(\n",
    "    data['Averaged supported activity of Bi-214 and Pb-214 (Bq/g)'],\n",
    "    data['Center point of interval'],\n",
    "    xerr=data['Background activity uncertainty (Bq/g)'],\n",
    "    fmt='-', color=supported_activity_color, label='Background Activity',\n",
    "    capsize=5, linewidth=1, ecolor=supported_activity_error_color\n",
    ")\n",
    "\n",
    "# Highlight missing intervals with brown spans\n",
    "for y in missing_depths:\n",
    "    plt.axhspan(y - 0.5, y + 0.5, alpha=0.5, color='brown',\n",
    "                label='Undetectable radioisotope' if y == missing_depths[0] else None)\n",
    "\n",
    "# Annotate the selected depths with rounded-up calendar years\n",
    "for i, depth in enumerate(data['Center point of interval']):\n",
    "    if depth in depths_to_label:\n",
    "        year_value = data['calendar years pre year of core'].iloc[i]\n",
    "        if not pd.isna(year_value):\n",
    "            plt.text(\n",
    "                data['Excess Pb-210 (Bq/g)'].iloc[i] + 0.05, depth,\n",
    "                f'{int(np.ceil(year_value))}',\n",
    "                fontsize=14, color='black', verticalalignment='center'\n",
    "            )\n",
    "\n",
    "plt.title(f\"{core_name} Age Model\", fontsize=18)\n",
    "plt.xlabel(\"Bq/unit\", fontsize=14)\n",
    "plt.ylabel(\"Depth (cm)\", fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0.01, 1)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, which='both', linestyle='-', linewidth=0.5, color='lightgray')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path, format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b281d3c7",
   "metadata": {},
   "source": [
    "# Well done!\n",
    "\n",
    "#### When you've finished, go to Cell > All Output > Clear to be ready for the next user of this script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
