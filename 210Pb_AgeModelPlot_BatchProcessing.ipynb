{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d518608",
   "metadata": {},
   "source": [
    "# Welcome to the 210Pb age model script v2.4.0 - BATCH PROCESSING!\n",
    "\n",
    "### <div style=\"text-align: right\"> Last modified by A.A. Lehrmann 1 December 2025 </div>\n",
    "\n",
    "\n",
    "### This script will process MULTIPLE cores at once!\n",
    "### It extracts radioisotope data from Canberra PDFs, runs the age model, and plots for each core\n",
    "\n",
    "**Expected folder structure:**\n",
    "```\n",
    "parent_folder/\n",
    "├── NBP1902_BC28_gamma spec data/\n",
    "│   ├── PDFs/\n",
    "│   │   └── (PDF files)\n",
    "│   └── weights.csv\n",
    "├── NBP2202_MC12_gamma spec data/\n",
    "│   ├── PDFs/\n",
    "│   │   └── (PDF files)\n",
    "│   └── weights.csv\n",
    "└── ...\n",
    "```\n",
    "(Each core has its own folder containing PDFs and weights file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a513b53",
   "metadata": {},
   "source": [
    "## Import libraries and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b4d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 1: import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e674ea42-dfe2-402d-b629-7919e8eb4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: --- Helper functions (same as original) ---\n",
    "import os, re, numpy as np, pandas as pd\n",
    "\n",
    "# Capture depth AND optional version (e.g., 21-24, 21-24cm, 21-24_v2, 21-24cm_v3, etc.)\n",
    "DEPTH_RE = re.compile(r'(\\d{1,3}-\\d{1,3})(?:cm)?(?:_v(\\d+))?(?=\\.|_|$)', re.IGNORECASE)\n",
    "\n",
    "def _depth_and_version(s: str):\n",
    "    base = os.path.basename(str(s))\n",
    "    m = DEPTH_RE.search(base)\n",
    "    if not m:\n",
    "        return None, 0\n",
    "    depth = m.group(1)                 # standardized like \"21-24\"\n",
    "    version = int(m.group(2)) if m.group(2) else 0\n",
    "    return depth, version\n",
    "\n",
    "def reshape_canberra_with_ptsrc_mixed(df_in: pd.DataFrame,\n",
    "                                      write_to: str | None = None,\n",
    "                                      ptsrc_cols: tuple[str,str] = (\"Pb-210\", \"Pb-210 error\")) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Works on a single mixed table (Canberra + PtSrc rows).\n",
    "    - For any duplicate depths on either side, keeps the **highest _vN**.\n",
    "    - Adds H/I/J = ['ptsrc_pb210','ptsrc_pb210 error','file ptsrc'] right after 'Pb-214 error'.\n",
    "    - Preserves your original header names (no renaming of 'error' columns).\n",
    "    \"\"\"\n",
    "    if \"File\" not in df_in.columns:\n",
    "        raise KeyError(\"Input dataframe must contain a 'File' column.\")\n",
    "\n",
    "    df = df_in.copy()\n",
    "\n",
    "    # Split rows by prefix\n",
    "    is_ptsrc = df[\"File\"].astype(str).str.startswith(\"PtSrc_\")\n",
    "    can_df = df.loc[~is_ptsrc].copy()\n",
    "    pt_df  = df.loc[ is_ptsrc].copy()\n",
    "\n",
    "    # Extract (depth, version) for both sides\n",
    "    can_df[[\"__depth__\",\"__ver__\"]] = can_df[\"File\"].apply(lambda s: pd.Series(_depth_and_version(s)))\n",
    "    pt_df[[\"__depth__\",\"__ver__\"]]  = pt_df[\"File\"].apply(lambda s: pd.Series(_depth_and_version(s)))\n",
    "\n",
    "    # **Prefer highest version for Canberra** when duplicates share the same depth\n",
    "    can_df = can_df.sort_values(\"__ver__\").drop_duplicates(subset=\"__depth__\", keep=\"last\")\n",
    "\n",
    "    # Pick value/error columns in PtSrc rows\n",
    "    val_col, err_col = ptsrc_cols\n",
    "    if val_col not in pt_df.columns or err_col not in pt_df.columns:\n",
    "        # Fallback: first two numeric columns\n",
    "        num_cols = [c for c in pt_df.columns if c != \"File\" and np.issubdtype(pt_df[c].dtype, np.number)]\n",
    "        if len(num_cols) < 2:\n",
    "            for c in pt_df.columns:\n",
    "                if c != \"File\":\n",
    "                    pt_df[c] = pd.to_numeric(pt_df[c], errors=\"coerce\")\n",
    "            num_cols = [c for c in pt_df.columns if c != \"File\" and np.issubdtype(pt_df[c].dtype, np.number)]\n",
    "        val_col, err_col = num_cols[:2]\n",
    "\n",
    "    # Reduce PtSrc to needed columns and **prefer highest version per depth**\n",
    "    q = pt_df.loc[:, [\"__depth__\", \"__ver__\", \"File\", val_col, err_col]].copy()\n",
    "    q.rename(columns={\n",
    "        \"File\": \"file ptsrc\",\n",
    "        val_col: \"ptsrc_pb210\",\n",
    "        err_col: \"ptsrc_pb210 error\"\n",
    "    }, inplace=True)\n",
    "    q[\"file ptsrc\"] = q[\"file ptsrc\"].map(lambda x: os.path.basename(str(x)))\n",
    "    q = q.sort_values(\"__ver__\").drop_duplicates(subset=\"__depth__\", keep=\"last\")\n",
    "\n",
    "    # Merge and clean\n",
    "    out = can_df.merge(q.drop(columns=\"__ver__\"), on=\"__depth__\", how=\"left\")\n",
    "    out.drop(columns=[\"__depth__\",\"__ver__\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    # Desired column order (keep original header names)\n",
    "    base = [\"File\",\"Pb-210\",\"Pb-210 error\",\"Bi-214\",\"Bi-214 error\",\"Pb-214\",\"Pb-214 error\"]\n",
    "    hij  = [\"ptsrc_pb210\",\"ptsrc_pb210 error\",\"file ptsrc\"]\n",
    "    others = [col for col in out.columns if col not in base + hij]\n",
    "    out = out[[c for c in base if c in out.columns] + hij + others]\n",
    "\n",
    "    if write_to:\n",
    "        out.to_csv(write_to, index=False)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch_setup",
   "metadata": {},
   "source": [
    "## Batch Processing Setup\n",
    "\n",
    "This cell will:\n",
    "1. Ask for the parent directory containing all core folders\n",
    "2. Detect all subdirectories as potential cores\n",
    "3. Let you configure global settings\n",
    "4. Process each core automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "batch_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Operator name:  Asmara A. Lehrmann\n",
      "Run date [YYYYMMDD] (Enter for 20251201):  \n",
      "Enter the parent folder path containing all core folders:  D:\\210Pb_thismachine\\cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 21 core folders:\n",
      "  • NBP1902_BC28_gamma spec data (detected year: 2019)\n",
      "  • NBP1902_JPC17_gamma spec data (detected year: 2019)\n",
      "  • NBP2002 MC30 (detected year: 2020)\n",
      "  • NBP2002_KC72_gamma spec data (detected year: 2020)\n",
      "  • NBP2202 MC12 (detected year: 2022)\n",
      "  • NBP2202_KC-24_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_KC04_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_KC06_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_KC15_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_KC17_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_KC20_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_KC21_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_KC22_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_KC23_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_KC25_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_KC26_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_MC05_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_MC12_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_MC19_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_MC28_gamma spec data (detected year: 2022)\n",
      "  • NBP2202_MC30_gamma spec data (detected year: 2022)\n",
      "\n",
      "=== Global Settings ===\n",
      "Multiple years detected: [2019, 2020, 2022]\n",
      "Will use individual years for each core based on cruise name.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Label depths with calendar years? (all/none/ask):  all\n",
      "Any intervals with undetectable radioisotopes? (yes/no/ask):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Will process 21 cores with global settings:\n",
      "  Operator: Asmara A. Lehrmann\n",
      "  Run date: 20251201\n",
      "  Year of core: Will use individual years per core\n",
      "  Depth labeling: all\n",
      "  Missing depths handling: no\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Proceed with batch processing? (yes/no):  yes\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Batch processing configuration\n",
    "SCRIPT_VERSION = \"v2.4.0_batch\"\n",
    "OPERATOR_NAME = input(\"Operator name: \").strip()\n",
    "_default = datetime.today().strftime(\"%Y%m%d\")\n",
    "_run = input(f\"Run date [YYYYMMDD] (Enter for {_default}): \").strip() or _default\n",
    "RUN_DATE = _run\n",
    "\n",
    "# Function to auto-detect year from cruise name\n",
    "def get_year_from_cruise_name(core_name: str) -> int | None:\n",
    "    \"\"\"\n",
    "    Extract year from NBP cruise name.\n",
    "    NBP2202 -> 2022\n",
    "    NBP2002 -> 2020\n",
    "    NBP1902 -> 2019\n",
    "    \"\"\"\n",
    "    match = re.search(r'NBP(\\d{2})(\\d{2})', core_name, re.IGNORECASE)\n",
    "    if match:\n",
    "        year_prefix = match.group(1)  # e.g., '22', '20', '19'\n",
    "        return 2000 + int(year_prefix)\n",
    "    return None\n",
    "\n",
    "# Get parent directory containing all core folders\n",
    "parent_dir = input(\"Enter the parent folder path containing all core folders: \").strip()\n",
    "parent_path = Path(parent_dir)\n",
    "\n",
    "if not parent_path.exists():\n",
    "    raise FileNotFoundError(f\"Directory not found: {parent_path}\")\n",
    "\n",
    "# Detect all subdirectories as potential cores\n",
    "# Core folders are typically named like NBP1902_BC28_gamma spec data\n",
    "all_folders = [d for d in parent_path.iterdir() if d.is_dir()]\n",
    "core_folders = all_folders  # All subdirectories are potential cores\n",
    "print(f\"\\nFound {len(core_folders)} core folders:\")\n",
    "\n",
    "# Auto-detect years from core names\n",
    "core_years = {}\n",
    "for folder in core_folders:\n",
    "    detected_year = get_year_from_cruise_name(folder.name)\n",
    "    core_years[folder.name] = detected_year\n",
    "    year_str = f\" (detected year: {detected_year})\" if detected_year else \" (year unknown)\"\n",
    "    print(f\"  • {folder.name}{year_str}\")\n",
    "\n",
    "# Check if all years were detected\n",
    "all_detected = all(year is not None for year in core_years.values())\n",
    "unique_years = set(y for y in core_years.values() if y is not None)\n",
    "\n",
    "# Get global settings\n",
    "print(\"\\n=== Global Settings ===\")\n",
    "if all_detected and len(unique_years) == 1:\n",
    "    default_year = list(unique_years)[0]\n",
    "    print(f\"All cores detected as year {default_year}\")\n",
    "    year_input = input(f\"Use {default_year} for all cores? (Enter to confirm, or type different year): \").strip()\n",
    "    default_year_of_core = int(year_input) if year_input else default_year\n",
    "elif all_detected:\n",
    "    print(f\"Multiple years detected: {sorted(unique_years)}\")\n",
    "    print(\"Will use individual years for each core based on cruise name.\")\n",
    "    default_year_of_core = None  # Will use per-core years\n",
    "else:\n",
    "    print(\"Some cores have unknown years. Will ask for each core individually.\")\n",
    "    default_year_of_core = None\n",
    "\n",
    "# Ask about depth labeling preference\n",
    "label_choice = input(\"\\nLabel depths with calendar years? (all/none/ask): \").strip().lower()\n",
    "if label_choice not in ['all', 'none', 'ask']:\n",
    "    label_choice = 'ask'\n",
    "\n",
    "# Ask about missing depths\n",
    "missing_choice = input(\"Any intervals with undetectable radioisotopes? (yes/no/ask): \").strip().lower()\n",
    "if missing_choice not in ['yes', 'no', 'ask']:\n",
    "    missing_choice = 'ask'\n",
    "\n",
    "print(f\"\\nWill process {len(core_folders)} cores with global settings:\")\n",
    "print(f\"  Operator: {OPERATOR_NAME}\")\n",
    "print(f\"  Run date: {RUN_DATE}\")\n",
    "if default_year_of_core:\n",
    "    print(f\"  Year of core: {default_year_of_core} (applies to all)\")\n",
    "else:\n",
    "    print(f\"  Year of core: Will use individual years per core\")\n",
    "print(f\"  Depth labeling: {label_choice}\")\n",
    "print(f\"  Missing depths handling: {missing_choice}\")\n",
    "\n",
    "proceed = input(\"\\nProceed with batch processing? (yes/no): \").strip().lower()\n",
    "if proceed != 'yes':\n",
    "    raise SystemExit(\"Batch processing cancelled by user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processing_section",
   "metadata": {},
   "source": [
    "## Core Processing Functions\n",
    "\n",
    "These cells contain all the processing logic from the original script, wrapped in functions for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extract_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: PDF extraction functions (from original script cells 6-10)\n",
    "\n",
    "def process_ptsrc_pdf(file_path, filename):\n",
    "    \"\"\"Process PtSrc PDF files (checks pages 3 and 4)\"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        if len(reader.pages) < 3:\n",
    "            print(f\"PDF file '{filename}' has less than 3 pages. Skipping.\")\n",
    "            return None\n",
    "        \n",
    "        # Try page 3 first (index 2), then page 4 (index 3)\n",
    "        pages_to_check = [2]  # Start with page 3\n",
    "        if len(reader.pages) >= 4:\n",
    "            pages_to_check.append(3)  # Add page 4 if it exists\n",
    "        \n",
    "        for page_idx in pages_to_check:\n",
    "            page = reader.pages[page_idx]\n",
    "            text = page.extract_text()\n",
    "            lines = text.split('\\n')\n",
    "            for line in lines:\n",
    "                if 'Pb-210' in line:\n",
    "                    ptsrc_pb210, PtSrc_Pb210error = line.split()[-2:]\n",
    "                    return {\n",
    "                        'File': filename,\n",
    "                        'Pb-210': float(ptsrc_pb210),\n",
    "                        'Pb-210 error': float(PtSrc_Pb210error)\n",
    "                    }\n",
    "        \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PtSrc PDF '{filename}': {e}\")\n",
    "        return None\n",
    "\n",
    "def process_regular_pdf(file_path, filename):\n",
    "    \"\"\"Process regular PDF files (checks pages 3 and 4)\"\"\"\n",
    "    pb210 = pb210error = Bi214 = Bi214error = Pb214 = Pb214error = None\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        if len(reader.pages) < 3:\n",
    "            print(f\"PDF file '{filename}' has less than 3 pages. Skipping.\")\n",
    "            return None\n",
    "        \n",
    "        # Try page 3 first (index 2), then page 4 (index 3)\n",
    "        pages_to_check = [2]  # Start with page 3\n",
    "        if len(reader.pages) >= 4:\n",
    "            pages_to_check.append(3)  # Add page 4 if it exists\n",
    "        \n",
    "        data_found = False\n",
    "        for page_idx in pages_to_check:\n",
    "            page = reader.pages[page_idx]\n",
    "            text = page.extract_text()\n",
    "            lines = text.split('\\n')\n",
    "            for line in lines:\n",
    "                if 'Pb-210' in line:\n",
    "                    pb210, pb210error = line.split()[-2:]\n",
    "                elif 'Bi-214' in line:\n",
    "                    Bi214, Bi214error = line.split()[-2:]\n",
    "                elif 'Pb-214' in line:\n",
    "                    Pb214, Pb214error = line.split()[-2:]\n",
    "            \n",
    "            # Check if we found all required data\n",
    "            if pb210 is not None and Bi214 is not None:\n",
    "                data_found = True\n",
    "                break\n",
    "        \n",
    "        if not data_found:\n",
    "            if pb210 is None or pb210error is None:\n",
    "                return None\n",
    "            if Bi214 is None or Bi214error is None:\n",
    "                return None\n",
    "        \n",
    "        if Pb214 is None or Pb214error is None:\n",
    "            Pb214 = Pb214error = 'NaN'\n",
    "        \n",
    "        return {\n",
    "            'File': filename,\n",
    "            'Pb-210': float(pb210),\n",
    "            'Pb-210 error': float(pb210error),\n",
    "            'Bi-214': float(Bi214),\n",
    "            'Bi-214 error': float(Bi214error),\n",
    "            'Pb-214': float(Pb214) if Pb214 != 'NaN' else float('nan'),\n",
    "            'Pb-214 error': float(Pb214error) if Pb214error != 'NaN' else float('nan')\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF file '{filename}': {e}\")\n",
    "        return None\n",
    "\n",
    "def process_pdf_file(file_path, filename):\n",
    "    \"\"\"Route to appropriate processor based on filename\"\"\"\n",
    "    if filename.startswith(\"PtSrc_\"):\n",
    "        return process_ptsrc_pdf(file_path, filename)\n",
    "    else:\n",
    "        return process_regular_pdf(file_path, filename)\n",
    "\n",
    "def extract_isotope_data_from_pdfs(folder_path):\n",
    "    \"\"\"\n",
    "    Extract radioisotope data from all PDFs in the specified folder.\n",
    "    Returns a list of dictionaries with isotope data.\n",
    "    \"\"\"\n",
    "    combined_data = []\n",
    "    folder_path = Path(folder_path)\n",
    "    \n",
    "    for pdf_file in folder_path.glob(\"*.pdf\"):\n",
    "        data = process_pdf_file(str(pdf_file), pdf_file.name)\n",
    "        if data is not None:\n",
    "            combined_data.append(data)\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "age_model_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Age model calculation functions (from original script cells 17-24)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def calculate_age_model(merged_data, year_of_core, missing_depths=[]):\n",
    "    \"\"\"\n",
    "    Calculate the age model from merged isotope and weight data.\n",
    "    Based on the Wellner Lab Group excel model (Appleby, 2001; Boldt et al., 2013)\n",
    "    \"\"\"\n",
    "    data = merged_data.copy()\n",
    "    \n",
    "    # Calculate interval properties\n",
    "    data['Center point of interval'] = (data['Top of interval (cm)'] + data['Base of interval (cm)']) / 2\n",
    "    data['Interval thickness (cm)'] = data['Base of interval (cm)'] - data['Top of interval (cm)']\n",
    "    \n",
    "    # Calculate activities\n",
    "    data['Pb-210 activity (Bq/g)'] = data['Pb-210'] / data['Weight (g)']\n",
    "    data['Pb-210 activity Uncertainty (Bq-g)'] = data['Pb-210 error'] / data['Weight (g)']\n",
    "    \n",
    "    data['Bi-214 activity (Bq/g)'] = data['Bi-214'] / data['Weight (g)']\n",
    "    data['Pb-214 activity (Bq/g)'] = data['Pb-214'] / data['Weight (g)']\n",
    "    \n",
    "    # Calculate supported activity\n",
    "    data['Averaged supported activity of Bi-214 and Pb-214 (Bq/g)'] = (\n",
    "        data['Bi-214 activity (Bq/g)'] + data['Pb-214 activity (Bq/g)']\n",
    "    ) / 2\n",
    "    \n",
    "    # Calculate uncertainties for background activity\n",
    "    data['Bi-214 uncertainty'] = data['Bi-214 error'] / data['Weight (g)']\n",
    "    data['Pb-214 uncertainty'] = data['Pb-214 error'] / data['Weight (g)']\n",
    "    data['Background activity uncertainty (Bq/g)'] = np.sqrt(\n",
    "        data['Bi-214 uncertainty']**2 + data['Pb-214 uncertainty']**2\n",
    "    ) / 2\n",
    "    \n",
    "    # Calculate excess Pb-210\n",
    "    data['Excess Pb-210 (Bq/g)'] = (\n",
    "        data['Pb-210 activity (Bq/g)'] - \n",
    "        data['Averaged supported activity of Bi-214 and Pb-214 (Bq/g)']\n",
    "    )\n",
    "    \n",
    "    # Handle missing/negative values\n",
    "    data.loc[data['Excess Pb-210 (Bq/g)'] < 0, 'Excess Pb-210 (Bq/g)'] = np.nan\n",
    "    \n",
    "    # CRS age model calculations\n",
    "    lambda_pb210 = np.log(2) / 22.3  # decay constant\n",
    "    \n",
    "    # Calculate cumulative inventory from bottom up\n",
    "    data['Excess Pb-210 inventory (Bq/cm2)'] = (\n",
    "        data['Excess Pb-210 (Bq/g)'] * \n",
    "        data['Weight (g)'] / \n",
    "        data['Interval thickness (cm)']\n",
    "    )\n",
    "    \n",
    "    data['Cumulative inventory from bottom'] = (\n",
    "        data['Excess Pb-210 inventory (Bq/cm2)'][::-1].cumsum()[::-1]\n",
    "    )\n",
    "    \n",
    "    # Calculate ages\n",
    "    total_inventory = data['Cumulative inventory from bottom'].iloc[0]\n",
    "    data['Age (years)'] = (1 / lambda_pb210) * np.log(\n",
    "        total_inventory / data['Cumulative inventory from bottom']\n",
    "    )\n",
    "    \n",
    "    # Calculate calendar years\n",
    "    data['calendar years pre year of core'] = year_of_core - data['Age (years)']\n",
    "    \n",
    "    # Calculate sedimentation rate\n",
    "    data['Sedimentation rate (cm/yr)'] = data['Interval thickness (cm)'] / data['Age (years)'].diff()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def compose_output_name(basename: str, ext: str, directory: Path | str, suffix: str) -> Path:\n",
    "    \"\"\"\n",
    "    Returns a full Path like <directory>/<basename>_<suffix><ext>\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    base = f\"{basename}{suffix}\"\n",
    "    if not ext.startswith(\".\"):\n",
    "        ext = \".\" + ext\n",
    "    return directory / f\"{base}{ext}\"\n",
    "\n",
    "def write_readme(filepath: Path, content: str):\n",
    "    \"\"\"Write a README file next to the output file\"\"\"\n",
    "    readme_path = filepath.parent / f\"{filepath.stem}_README.txt\"\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "plotting_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Plotting functions (from original script cells 27-30)\n",
    "\n",
    "def save_figure(fig, basename: str, directory: Path, ext: str, dpi: int, \n",
    "                meta: dict, readme_content: str = \"\"):\n",
    "    \"\"\"\n",
    "    Save figure with metadata footer and optional README.\n",
    "    \"\"\"\n",
    "    # Remove any existing footer text\n",
    "    for ax in fig.axes:\n",
    "        for t in ax.texts:\n",
    "            if hasattr(t, 'get_gid') and t.get_gid() == 'footer':\n",
    "                try:\n",
    "                    t.remove()\n",
    "                except Exception:\n",
    "                    pass\n",
    "    \n",
    "    # Add footer to first axes\n",
    "    ax = fig.axes[0]\n",
    "    footer = ax.text(\n",
    "        1.01, 0.5, f\"Created by {meta['operator']} with 210PbAgeModelScript {meta['version']}\",\n",
    "        ha=\"left\", va=\"center\", rotation=270, fontsize=9,\n",
    "        color=\"lightgrey\", transform=ax.transAxes\n",
    "    )\n",
    "    footer.set_gid(\"footer\")\n",
    "    \n",
    "    # Save figure\n",
    "    suffix = f\"_{meta['core']}_{meta['date']}\"\n",
    "    out_path = compose_output_name(basename, ext, directory, suffix)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    \n",
    "    print(f\"Figure saved -> {out_path}\")\n",
    "    if readme_content:\n",
    "        write_readme(out_path, readme_content)\n",
    "    \n",
    "    return out_path\n",
    "\n",
    "def plot_uncorrected_activity(data, core_name, missing_depths, save_location, meta):\n",
    "    \"\"\"\n",
    "    Plot Pb-210 uncorrected activity.\n",
    "    \"\"\"\n",
    "    # Color scheme\n",
    "    excess_pb210_color = '#3B5BA5'\n",
    "    excess_pb210_error_color = '#6B8DD6'\n",
    "    \n",
    "    plt.figure(figsize=(3, 5))\n",
    "    plt.errorbar(\n",
    "        data['Pb-210 activity (Bq/g)'], data['Center point of interval'], \n",
    "        xerr=data['Pb-210 activity Uncertainty (Bq-g)'], fmt='-', \n",
    "        color=excess_pb210_color, label='Pb-210 activity (Bq/unit)', \n",
    "        capsize=5, linewidth=1, ecolor=excess_pb210_error_color\n",
    "    )\n",
    "    plt.xscale('log')\n",
    "    plt.xlim(0.01, 10)\n",
    "    \n",
    "    # Highlight missing intervals\n",
    "    for y in missing_depths:\n",
    "        plt.axhspan(y - 0.5, y + 0.5, alpha=0.5, color='brown', \n",
    "                    label='Undetectable radioisotope' if y == missing_depths[0] else None)\n",
    "    \n",
    "    plt.title(f\"{core_name} 210 Pb Uncorrected Activity\", fontsize=18)\n",
    "    plt.xlabel(\"Bq/g\", fontsize=14)\n",
    "    plt.ylabel(\"Depth (cm)\", fontsize=14)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, which='both', linestyle='-', linewidth=0.5, color='lightgray')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=1)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    save_figure(fig, basename=\"UncorrectedActivity\", directory=save_location, \n",
    "                ext=\".pdf\", dpi=300, meta=meta)\n",
    "    plt.close()\n",
    "\n",
    "def plot_age_model(data, core_name, missing_depths, depths_to_label, save_location, meta):\n",
    "    \"\"\"\n",
    "    Plot the full age model with excess Pb-210 and background activity.\n",
    "    \"\"\"\n",
    "    # Color scheme\n",
    "    excess_pb210_color = '#3B5BA5'\n",
    "    excess_pb210_error_color = '#6B8DD6'\n",
    "    supported_activity_color = '#C5462D'\n",
    "    supported_activity_error_color = '#E67E6B'\n",
    "    \n",
    "    plt.figure(figsize=(5, 10))\n",
    "    \n",
    "    # Calculate errors\n",
    "    yerr = np.abs(data['Center point of interval'] - data['Top of interval (cm)'])\n",
    "    xerr = data['Pb-210 activity Uncertainty (Bq-g)']\n",
    "    \n",
    "    # Plot Excess Pb-210 with connecting line\n",
    "    valid_mask_excess = ~data['Excess Pb-210 (Bq/g)'].isna()\n",
    "    plt.plot(\n",
    "        data.loc[valid_mask_excess, 'Excess Pb-210 (Bq/g)'], \n",
    "        data.loc[valid_mask_excess, 'Center point of interval'],\n",
    "        color=excess_pb210_color, linewidth=1, zorder=1\n",
    "    )\n",
    "    \n",
    "    # Draw error boxes for Excess Pb-210\n",
    "    for i in range(len(data)):\n",
    "        x = data['Excess Pb-210 (Bq/g)'].iloc[i]\n",
    "        y = data['Center point of interval'].iloc[i]\n",
    "        \n",
    "        if pd.isna(x):\n",
    "            continue\n",
    "        \n",
    "        width = xerr.iloc[i] * 2\n",
    "        height = yerr.iloc[i] * 2\n",
    "        rect = patches.Rectangle(\n",
    "            (x - xerr.iloc[i], y - yerr.iloc[i]), width, height,\n",
    "            linewidth=0.5, edgecolor='grey', facecolor='none'\n",
    "        )\n",
    "        plt.gca().add_patch(rect)\n",
    "    \n",
    "    # Plot background activity\n",
    "    valid_mask_bg = ~data['Averaged supported activity of Bi-214 and Pb-214 (Bq/g)'].isna()\n",
    "    plt.errorbar(\n",
    "        data.loc[valid_mask_bg, 'Averaged supported activity of Bi-214 and Pb-214 (Bq/g)'],\n",
    "        data.loc[valid_mask_bg, 'Center point of interval'],\n",
    "        xerr=data.loc[valid_mask_bg, 'Background activity uncertainty (Bq/g)'],\n",
    "        fmt='-', color=supported_activity_color, label='Background Activity',\n",
    "        capsize=5, linewidth=1, ecolor=supported_activity_error_color\n",
    "    )\n",
    "    \n",
    "    # Highlight missing intervals\n",
    "    for y in missing_depths:\n",
    "        plt.axhspan(y - 0.5, y + 0.5, alpha=0.5, color='brown',\n",
    "                    label='Undetectable radioisotope' if y == missing_depths[0] else None)\n",
    "    \n",
    "    # Annotate selected depths with calendar years\n",
    "    for i, depth in enumerate(data['Center point of interval']):\n",
    "        if depth in depths_to_label:\n",
    "            year_value = data['calendar years pre year of core'].iloc[i]\n",
    "            if not pd.isna(year_value):\n",
    "                plt.text(\n",
    "                    data['Excess Pb-210 (Bq/g)'].iloc[i] + 0.05, depth,\n",
    "                    f'{int(np.ceil(year_value))}',\n",
    "                    fontsize=14, color='black', verticalalignment='center'\n",
    "                )\n",
    "    \n",
    "    plt.title(f\"{core_name} Age Model\", fontsize=18)\n",
    "    plt.xlabel(\"Bq/unit\", fontsize=14)\n",
    "    plt.ylabel(\"Depth (cm)\", fontsize=14)\n",
    "    plt.xscale('log')\n",
    "    plt.xlim(0.01, 2)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, which='both', linestyle='-', linewidth=0.5, color='lightgray')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=1)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    save_figure(fig, basename=\"AgeModelPlot\", directory=save_location, \n",
    "                ext=\".pdf\", dpi=300, meta=meta)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "main_processing",
   "metadata": {},
   "source": [
    "## Main Batch Processing Loop\n",
    "\n",
    "This cell processes each core folder automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "batch_loop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing core 1/21: NBP1902_BC28_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP1902BC28gammaspecdata\n",
      "  PDFs found in root of core folder (34 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP1902_BC28_gamma spec data\n",
      "  DEBUG: Found 35 PDF files\n",
      "PDF file 'AgeModelPlot_NBP1902BC28_20250911.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 32 PDFs\n",
      "  ✗ ERROR processing NBP1902_BC28_gamma spec data:\n",
      "    [Errno 13] Permission denied: 'D:\\\\210Pb_thismachine\\\\cores\\\\NBP1902_BC28_gamma spec data\\\\CanberraData_NBP1902BC28gammaspecdata_20251201.csv'\n",
      "\n",
      "================================================================================\n",
      "Processing core 2/21: NBP1902_JPC17_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP1902JPC17gammaspecdata\n",
      "  PDFs found in root of core folder (12 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP1902_JPC17_gamma spec data\n",
      "  DEBUG: Found 12 PDF files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aalehrma\\AppData\\Local\\Temp\\ipykernel_14052\\3434979222.py\", line 68, in <module>\n",
      "    df_processed = reshape_canberra_with_ptsrc_mixed(df_isotopes, write_to=output_csv_path)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\aalehrma\\AppData\\Local\\Temp\\ipykernel_14052\\519063308.py\", line 75, in reshape_canberra_with_ptsrc_mixed\n",
      "    out.to_csv(write_to, index=False)\n",
      "  File \"C:\\Users\\aalehrma\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\util\\_decorators.py\", line 333, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\aalehrma\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py\", line 3986, in to_csv\n",
      "    return DataFrameRenderer(formatter).to_csv(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\aalehrma\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1014, in to_csv\n",
      "    csv_formatter.save()\n",
      "  File \"C:\\Users\\aalehrma\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py\", line 251, in save\n",
      "    with get_handle(\n",
      "         ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\aalehrma\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\io\\common.py\", line 873, in get_handle\n",
      "    handle = open(\n",
      "             ^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: 'D:\\\\210Pb_thismachine\\\\cores\\\\NBP1902_BC28_gamma spec data\\\\CanberraData_NBP1902BC28gammaspecdata_20251201.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracted data from 12 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP1902JPC17gammaspecdata_20251201.csv\n",
      "  WARNING: No weights file found in NBP1902_JPC17_gamma spec data, skipping\n",
      "\n",
      "================================================================================\n",
      "Processing core 3/21: NBP2002 MC30\n",
      "================================================================================\n",
      "Core name: NBP2002MC30\n",
      "  PDFs found in root of core folder (30 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2002 MC30\n",
      "  DEBUG: Found 30 PDF files\n",
      "  Extracted data from 30 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2002MC30_20251201.csv\n",
      "  Weights file: NBP2002MC30_weights_aal.csv\n",
      "  DEBUG: Weights file has 15 rows\n",
      "  DEBUG: Weights columns: ['Core', 'top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'Sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 10, 12], base=[1, 11, 13]\n",
      "  DEBUG: Sample weight tops: [0, 2, 3]\n",
      "  DEBUG: Sample weight bases: [1, 3, 4]\n",
      "  DEBUG: After merge: 15 rows\n",
      "  Merged 15 samples\n",
      "  Using detected year: 2020\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2002MC30_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2002 MC30\\outputs\\UncorrectedActivity_NBP2002MC30_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2002 MC30\\outputs\\AgeModelPlot_NBP2002MC30_20251201.pdf\n",
      "  ✓ Successfully processed NBP2002MC30\n",
      "\n",
      "================================================================================\n",
      "Processing core 4/21: NBP2002_KC72_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2002KC72gammaspecdata\n",
      "  PDFs found in root of core folder (38 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2002_KC72_gamma spec data\n",
      "  DEBUG: Found 42 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2002KC70_20250909.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'AgeModelPlot_NBP2002KC72_20250904.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'AgeModelPlot_NBP2002KC72_20250909.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'AgeModelPlot_NBP2002KC72_20250911.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 38 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2002KC72gammaspecdata_20251201.csv\n",
      "  WARNING: No weights file found in NBP2002_KC72_gamma spec data, skipping\n",
      "\n",
      "================================================================================\n",
      "Processing core 5/21: NBP2202 MC12\n",
      "================================================================================\n",
      "Core name: NBP2202MC12\n",
      "  PDFs found in root of core folder (42 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202 MC12\n",
      "  DEBUG: Found 45 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202MC1220250903.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'AgeModelPlot_NBP2202MC12_20250911.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'AgeModelPlot_NBP2202MC12_20251120.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'NBP2202 MC12 Age model 23 June 2025_Age_Model.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'NBP2202 MC12 age model July 2025_Age_Model.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 40 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202MC12_20251201.csv\n",
      "  Weights file: NBP2202_MC12_weights.csv\n",
      "  DEBUG: Weights file has 19 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 4, 36], base=[1, 5, 37]\n",
      "  DEBUG: Sample weight tops: [0, 1, 2]\n",
      "  DEBUG: Sample weight bases: [1, 2, 3]\n",
      "  DEBUG: After merge: 19 rows\n",
      "  Merged 19 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202MC12_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202 MC12\\outputs\\UncorrectedActivity_NBP2202MC12_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202 MC12\\outputs\\AgeModelPlot_NBP2202MC12_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202MC12\n",
      "\n",
      "================================================================================\n",
      "Processing core 6/21: NBP2202_KC-24_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC24gammaspecdata\n",
      "  PDFs found in root of core folder (25 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC-24_gamma spec data\n",
      "  DEBUG: Found 26 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202KC24_20251106.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 25 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC24gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC24_weights.csv\n",
      "  DEBUG: Weights file has 13 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 12, 15], base=[3, 15, 18]\n",
      "  DEBUG: Sample weight tops: [0, 3, 6]\n",
      "  DEBUG: Sample weight bases: [3, 6, 9]\n",
      "  DEBUG: After merge: 13 rows\n",
      "  Merged 13 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC24gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC-24_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC24gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC-24_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC24gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC24gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 7/21: NBP2202_KC04_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC04gammaspecdata\n",
      "  PDFs found in root of core folder (25 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC04_gamma spec data\n",
      "  DEBUG: Found 25 PDF files\n",
      "PDF file 'NBP2202 KC04_Age_Model.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 24 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC04gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC04_weights.csv\n",
      "  DEBUG: Weights file has 9 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 10, 12], base=[2, 12, 15]\n",
      "  DEBUG: Sample weight tops: [0, 3, 6]\n",
      "  DEBUG: Sample weight bases: [2, 6, 9]\n",
      "  DEBUG: After merge: 9 rows\n",
      "  Merged 9 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC04gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC04_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC04gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC04_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC04gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC04gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 8/21: NBP2202_KC06_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC06gammaspecdata\n",
      "  PDFs found in root of core folder (21 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC06_gamma spec data\n",
      "  DEBUG: Found 21 PDF files\n",
      "PDF file 'NBP2202 KC06_Age_Model.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 20 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC06gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC06_weights.csv\n",
      "  DEBUG: Weights file has 9 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 10, 12], base=[2, 12, 14]\n",
      "  DEBUG: Sample weight tops: [0, 2, 4]\n",
      "  DEBUG: Sample weight bases: [2, 4, 6]\n",
      "  DEBUG: After merge: 9 rows\n",
      "  Merged 9 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC06gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC06_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC06gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC06_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC06gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC06gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 9/21: NBP2202_KC15_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC15gammaspecdata\n",
      "  PDFs found in root of core folder (23 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC15_gamma spec data\n",
      "  DEBUG: Found 24 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202KC15_20251120.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'NBP2202 KC15 20250710_Age_Model.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 22 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC15gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC15_weights.csv\n",
      "  DEBUG: Weights file has 10 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 12, 14], base=[2, 14, 16]\n",
      "  DEBUG: Sample weight tops: [0, 4, 12]\n",
      "  DEBUG: Sample weight bases: [2, 6, 14]\n",
      "  DEBUG: After merge: 10 rows\n",
      "  Merged 10 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC15gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC15_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC15gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC15_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC15gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC15gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 10/21: NBP2202_KC17_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC17gammaspecdata\n",
      "  PDFs found in root of core folder (24 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC17_gamma spec data\n",
      "  DEBUG: Found 26 PDF files\n",
      "PDF file 'AgeModelPlot_KC17_20251106.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'AgeModelPlot_NBP2202KC17_20251106.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 24 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC17gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC17_weights.csv\n",
      "  DEBUG: Weights file has 12 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 10, 12], base=[2, 12, 14]\n",
      "  DEBUG: Sample weight tops: [0, 2, 4]\n",
      "  DEBUG: Sample weight bases: [2, 4, 6]\n",
      "  DEBUG: After merge: 12 rows\n",
      "  Merged 12 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC17gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC17_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC17gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC17_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC17gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC17gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 11/21: NBP2202_KC20_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC20gammaspecdata\n",
      "  PDFs found in root of core folder (20 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC20_gamma spec data\n",
      "  DEBUG: Found 22 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202KC20_20250922.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'AgeModelPlot_NBP2202KC20_20251124.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 20 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC20gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC20_weights.csv\n",
      "  DEBUG: Weights file has 9 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 12, 15], base=[3, 15, 18]\n",
      "  DEBUG: Sample weight tops: [0, 3, 6]\n",
      "  DEBUG: Sample weight bases: [3, 6, 9]\n",
      "  DEBUG: After merge: 9 rows\n",
      "  Merged 9 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC20gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC20_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC20gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC20_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC20gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC20gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 12/21: NBP2202_KC21_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC21gammaspecdata\n",
      "  PDFs found in root of core folder (47 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC21_gamma spec data\n",
      "  DEBUG: Found 48 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202KC21_20251106.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 40 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC21gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC21_weights.csv\n",
      "  DEBUG: Weights file has 15 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[24, 20, 2], base=[26, 22, 4]\n",
      "  DEBUG: Sample weight tops: [0, 2, 4]\n",
      "  DEBUG: Sample weight bases: [2, 4, 6]\n",
      "  DEBUG: After merge: 11 rows\n",
      "  Merged 11 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC21gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC21_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC21gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC21_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC21gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC21gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 13/21: NBP2202_KC22_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC22gammaspecdata\n",
      "  PDFs found in root of core folder (92 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC22_gamma spec data\n",
      "  DEBUG: Found 93 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202KC22_20251106.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 92 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC22gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC22_weights.csv\n",
      "  DEBUG: Weights file has 46 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 35, 37], base=[1, 36, 38]\n",
      "  DEBUG: Sample weight tops: [0, 1, 2]\n",
      "  DEBUG: Sample weight bases: [1, 2, 3]\n",
      "  DEBUG: After merge: 46 rows\n",
      "  Merged 46 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC22gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC22_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC22gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC22_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC22gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC22gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 14/21: NBP2202_KC23_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC23gammaspecdata\n",
      "  PDFs found in root of core folder (16 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC23_gamma spec data\n",
      "  DEBUG: Found 17 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202KC23_20251106.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 16 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC23gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC25_weights.csv\n",
      "  DEBUG: Weights file has 15 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 10, 12], base=[2, 12, 14]\n",
      "  DEBUG: Sample weight tops: [0, 2, 4]\n",
      "  DEBUG: Sample weight bases: [2, 4, 6]\n",
      "  DEBUG: After merge: 8 rows\n",
      "  Merged 8 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC23gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC23_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC23gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC23_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC23gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC23gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 15/21: NBP2202_KC25_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC25gammaspecdata\n",
      "  PDFs found in root of core folder (31 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC25_gamma spec data\n",
      "  DEBUG: Found 32 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202KC25_20251106.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 31 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC25gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC25_weights.csv\n",
      "  DEBUG: Weights file has 15 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 10, 12], base=[2, 12, 14]\n",
      "  DEBUG: Sample weight tops: [0, 2, 4]\n",
      "  DEBUG: Sample weight bases: [2, 4, 6]\n",
      "  DEBUG: After merge: 14 rows\n",
      "  Merged 14 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC25gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC25_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC25gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC25_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC25gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC25gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 16/21: NBP2202_KC26_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202KC26gammaspecdata\n",
      "  PDFs found in root of core folder (53 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_KC26_gamma spec data\n",
      "  DEBUG: Found 54 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202KC26_20251106.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 45 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202KC26gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_KC26_weights.csv\n",
      "  DEBUG: Weights file has 15 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 52, 48], base=[2, 54, 50]\n",
      "  DEBUG: Sample weight tops: [0, 12, 16]\n",
      "  DEBUG: Sample weight bases: [2, 14, 18]\n",
      "  DEBUG: After merge: 15 rows\n",
      "  Merged 15 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202KC26gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC26_gamma spec data\\outputs\\UncorrectedActivity_NBP2202KC26gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_KC26_gamma spec data\\outputs\\AgeModelPlot_NBP2202KC26gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202KC26gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 17/21: NBP2202_MC05_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202MC05gammaspecdata\n",
      "  PDFs found in root of core folder (24 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_MC05_gamma spec data\n",
      "  DEBUG: Found 24 PDF files\n",
      "  Extracted data from 24 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202MC05gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_MC30_weights.csv\n",
      "  DEBUG: Weights file has 14 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 19, 2], base=[1, 20, 3]\n",
      "  DEBUG: Sample weight tops: [0, 1, 2]\n",
      "  DEBUG: Sample weight bases: [1, 2, 3]\n",
      "  DEBUG: After merge: 4 rows\n",
      "  Merged 4 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202MC05gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_MC05_gamma spec data\\outputs\\UncorrectedActivity_NBP2202MC05gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_MC05_gamma spec data\\outputs\\AgeModelPlot_NBP2202MC05gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202MC05gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 18/21: NBP2202_MC12_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202MC12gammaspecdata\n",
      "  PDFs found in root of core folder (42 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_MC12_gamma spec data\n",
      "  DEBUG: Found 42 PDF files\n",
      "  Extracted data from 42 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202MC12gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_MC12_weights.csv\n",
      "  DEBUG: Weights file has 37 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 4, 36], base=[1, 5, 37]\n",
      "  DEBUG: Sample weight tops: [0, 1, 2]\n",
      "  DEBUG: Sample weight bases: [1, 2, 3]\n",
      "  DEBUG: After merge: 21 rows\n",
      "  Merged 21 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202MC12gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_MC12_gamma spec data\\outputs\\UncorrectedActivity_NBP2202MC12gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_MC12_gamma spec data\\outputs\\AgeModelPlot_NBP2202MC12gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202MC12gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 19/21: NBP2202_MC19_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202MC19gammaspecdata\n",
      "  PDFs found in root of core folder (44 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_MC19_gamma spec data\n",
      "  DEBUG: Found 44 PDF files\n",
      "  Extracted data from 44 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202MC19gammaspecdata_20251201.csv\n",
      "  WARNING: No weights file found in NBP2202_MC19_gamma spec data, skipping\n",
      "\n",
      "================================================================================\n",
      "Processing core 20/21: NBP2202_MC28_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202MC28gammaspecdata\n",
      "  PDFs found in root of core folder (55 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_MC28_gamma spec data\n",
      "  DEBUG: Found 56 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202MC28_20251120.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'PtSrc_NBP2202_MC28_17-18.PDF' has less than 3 pages. Skipping.\n",
      "  Extracted data from 54 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202MC28gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_MC28_weights.csv\n",
      "  DEBUG: Weights file has 39 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 4, 38], base=[1, 5, 39]\n",
      "  DEBUG: Sample weight tops: [0, 1, 2]\n",
      "  DEBUG: Sample weight bases: [1, 2, 3]\n",
      "  DEBUG: After merge: 29 rows\n",
      "  Merged 29 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202MC28gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_MC28_gamma spec data\\outputs\\UncorrectedActivity_NBP2202MC28gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_MC28_gamma spec data\\outputs\\AgeModelPlot_NBP2202MC28gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202MC28gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "Processing core 21/21: NBP2202_MC30_gamma spec data\n",
      "================================================================================\n",
      "Core name: NBP2202MC30gammaspecdata\n",
      "  PDFs found in root of core folder (29 files)\n",
      "  Extracting isotope data from PDFs...\n",
      "  DEBUG: Looking for PDFs in: D:\\210Pb_thismachine\\cores\\NBP2202_MC30_gamma spec data\n",
      "  DEBUG: Found 31 PDF files\n",
      "PDF file 'AgeModelPlot_NBP2202MC30_20251120.pdf' has less than 3 pages. Skipping.\n",
      "PDF file 'AgeModelPlot_NBP2202MC30_20251124.pdf' has less than 3 pages. Skipping.\n",
      "  Extracted data from 29 PDFs\n",
      "  Saved Canberra data to CanberraData_NBP2202MC30gammaspecdata_20251201.csv\n",
      "  Weights file: NBP2202_MC30_weights.csv\n",
      "  DEBUG: Weights file has 14 rows\n",
      "  DEBUG: Weights columns: ['Core', 'Top of interval (cm)', 'Center point of interval', 'Base of interval (cm)', 'sediment weight (g)']\n",
      "  DEBUG: Sample processed depths: top=[0, 1, 10], base=[1, 2, 11]\n",
      "  DEBUG: Sample weight tops: [0, 1, 2]\n",
      "  DEBUG: Sample weight bases: [1, 2, 3]\n",
      "  DEBUG: After merge: 14 rows\n",
      "  Merged 14 samples\n",
      "  Using detected year: 2022\n",
      "  Calculating age model...\n",
      "  Saved age model data to AgeModelData_NBP2202MC30gammaspecdata_20251201.csv\n",
      "  Creating plots...\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_MC30_gamma spec data\\outputs\\UncorrectedActivity_NBP2202MC30gammaspecdata_20251201.pdf\n",
      "Figure saved -> D:\\210Pb_thismachine\\cores\\NBP2202_MC30_gamma spec data\\outputs\\AgeModelPlot_NBP2202MC30gammaspecdata_20251201.pdf\n",
      "  ✓ Successfully processed NBP2202MC30gammaspecdata\n",
      "\n",
      "================================================================================\n",
      "BATCH PROCESSING COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Successfully processed: 17 cores\n",
      "  ✓ NBP2002MC30 -> D:\\210Pb_thismachine\\cores\\NBP2002 MC30\\outputs\n",
      "  ✓ NBP2202MC12 -> D:\\210Pb_thismachine\\cores\\NBP2202 MC12\\outputs\n",
      "  ✓ NBP2202KC24gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC-24_gamma spec data\\outputs\n",
      "  ✓ NBP2202KC04gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC04_gamma spec data\\outputs\n",
      "  ✓ NBP2202KC06gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC06_gamma spec data\\outputs\n",
      "  ✓ NBP2202KC15gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC15_gamma spec data\\outputs\n",
      "  ✓ NBP2202KC17gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC17_gamma spec data\\outputs\n",
      "  ✓ NBP2202KC20gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC20_gamma spec data\\outputs\n",
      "  ✓ NBP2202KC21gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC21_gamma spec data\\outputs\n",
      "  ✓ NBP2202KC22gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC22_gamma spec data\\outputs\n",
      "  ✓ NBP2202KC23gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC23_gamma spec data\\outputs\n",
      "  ✓ NBP2202KC25gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC25_gamma spec data\\outputs\n",
      "  ✓ NBP2202KC26gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_KC26_gamma spec data\\outputs\n",
      "  ✓ NBP2202MC05gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_MC05_gamma spec data\\outputs\n",
      "  ✓ NBP2202MC12gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_MC12_gamma spec data\\outputs\n",
      "  ✓ NBP2202MC28gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_MC28_gamma spec data\\outputs\n",
      "  ✓ NBP2202MC30gammaspecdata -> D:\\210Pb_thismachine\\cores\\NBP2202_MC30_gamma spec data\\outputs\n",
      "\n",
      "Failed to process: 4 cores\n",
      "  ✗ NBP1902_BC28_gamma spec data: [Errno 13] Permission denied: 'D:\\\\210Pb_thismachine\\\\cores\\\\NBP1902_BC28_gamma spec data\\\\CanberraData_NBP1902BC28gammaspecdata_20251201.csv'\n",
      "  ✗ NBP1902JPC17gammaspecdata: No weights file found\n",
      "  ✗ NBP2002KC72gammaspecdata: No weights file found\n",
      "  ✗ NBP2202MC19gammaspecdata: No weights file found\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Main batch processing loop\n",
    "\n",
    "# Track results\n",
    "results = []\n",
    "failed_cores = []\n",
    "\n",
    "for core_idx, core_folder in enumerate(core_folders, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing core {core_idx}/{len(core_folders)}: {core_folder.name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract core name from folder name\n",
    "        CORE_NAME_RAW = core_folder.name\n",
    "        CORE_NAME = re.sub(r\"[^A-Za-z0-9]+\", \"\", CORE_NAME_RAW)\n",
    "        SUFFIX = f\"_{CORE_NAME}_{RUN_DATE}\"\n",
    "        \n",
    "        META = {\n",
    "            \"operator\": OPERATOR_NAME, \n",
    "            \"date\": RUN_DATE, \n",
    "            \"core\": CORE_NAME, \n",
    "            \"version\": SCRIPT_VERSION, \n",
    "            \"suffix\": SUFFIX\n",
    "        }\n",
    "        \n",
    "        print(f\"Core name: {CORE_NAME}\")\n",
    "        \n",
    "        # Find PDFs folder inside this core folder, or use core folder directly\n",
    "        # Exclude output files like AgeModelPlot\n",
    "        pdf_folders = [d for d in core_folder.glob(\"*[Pp][Dd][Ff]*\") \n",
    "                      if d.is_dir()]  # Only directories\n",
    "        \n",
    "        if pdf_folders:\n",
    "            folder_path = pdf_folders[0]\n",
    "            print(f\"  PDF folder: {folder_path.name}\")\n",
    "        else:\n",
    "            # Check if PDFs are directly in the core folder\n",
    "            # Look for source PDFs (exclude output PDFs like AgeModelPlot)\n",
    "            pdf_files = [f for f in core_folder.glob(\"*.pdf\") \n",
    "                        if not f.name.startswith(('AgeModelPlot', 'CanberraData'))]\n",
    "            if pdf_files:\n",
    "                folder_path = core_folder\n",
    "                print(f\"  PDFs found in root of core folder ({len(pdf_files)} files)\")\n",
    "            else:\n",
    "                print(f\"  WARNING: No source PDFs found in {CORE_NAME_RAW}, skipping\")\n",
    "                failed_cores.append((CORE_NAME, \"No source PDFs found\"))\n",
    "                continue\n",
    "        \n",
    "        # Extract isotope data from PDFs\n",
    "        print(f\"  Extracting isotope data from PDFs...\")\n",
    "        print(f\"  DEBUG: Looking for PDFs in: {folder_path}\")\n",
    "        pdf_files = list(Path(folder_path).glob(\"*.pdf\"))\n",
    "        print(f\"  DEBUG: Found {len(pdf_files)} PDF files\")\n",
    "        if pdf_files and len(pdf_files) <= 3:\n",
    "            print(f\"  DEBUG: PDF files: {[p.name for p in pdf_files]}\")\n",
    "        isotope_data = extract_isotope_data_from_pdfs(folder_path)\n",
    "        \n",
    "        if not isotope_data:\n",
    "            print(f\"  WARNING: No isotope data extracted, skipping {CORE_NAME}\")\n",
    "            failed_cores.append((CORE_NAME, \"No isotope data extracted\"))\n",
    "            continue\n",
    "        \n",
    "        df_isotopes = pd.DataFrame(isotope_data)\n",
    "        print(f\"  Extracted data from {len(df_isotopes)} PDFs\")\n",
    "        \n",
    "        # Process with PtSrc if available\n",
    "        output_csv_path = compose_output_name(\"CanberraData\", \".csv\", folder_path, SUFFIX)\n",
    "        df_processed = reshape_canberra_with_ptsrc_mixed(df_isotopes, write_to=output_csv_path)\n",
    "        print(f\"  Saved Canberra data to {output_csv_path.name}\")\n",
    "        \n",
    "        # Find weights file inside the core folder\n",
    "        weights_pattern = ['*weights*.csv', '*_weights.csv', '*-weights.csv']\n",
    "        weights_files = []\n",
    "        for pattern in weights_pattern:\n",
    "            weights_files.extend(core_folder.glob(pattern))\n",
    "        \n",
    "        if not weights_files:\n",
    "            print(f\"  WARNING: No weights file found in {CORE_NAME_RAW}, skipping\")\n",
    "            failed_cores.append((CORE_NAME, \"No weights file found\"))\n",
    "            continue\n",
    "        \n",
    "        weights_path = weights_files[0]\n",
    "        print(f\"  Weights file: {weights_path.name}\")\n",
    "        \n",
    "        # Load and merge data\n",
    "        df_weights = pd.read_csv(weights_path)\n",
    "        \n",
    "        print(f\"  DEBUG: Weights file has {len(df_weights)} rows\")\n",
    "        print(f\"  DEBUG: Weights columns: {list(df_weights.columns)}\")\n",
    "        \n",
    "        # Extract top and base depths from PDF filenames\n",
    "        # e.g., \"NBP1902_BC28_9-10cm.PDF\" -> top=9, base=10\n",
    "        depth_extract = df_processed['File'].str.extract(r'(\\d+)-(\\d+)')\n",
    "        df_processed['top'] = pd.to_numeric(depth_extract[0])\n",
    "        df_processed['base'] = pd.to_numeric(depth_extract[1])\n",
    "        \n",
    "        print(f\"  DEBUG: Sample processed depths: top={df_processed['top'].head(3).tolist()}, base={df_processed['base'].head(3).tolist()}\")\n",
    "        \n",
    "        # Identify weight file columns (assuming columns B, C, D are top, center, base)\n",
    "        # Column A is core name, so we use columns 1, 2, 3 (0-indexed)\n",
    "        if len(df_weights.columns) >= 4:\n",
    "            df_weights['top'] = pd.to_numeric(df_weights.iloc[:, 1])\n",
    "            df_weights['center'] = pd.to_numeric(df_weights.iloc[:, 2])\n",
    "            df_weights['base'] = pd.to_numeric(df_weights.iloc[:, 3])\n",
    "            if len(df_weights.columns) >= 5:\n",
    "                df_weights['Weight (g)'] = pd.to_numeric(df_weights.iloc[:, 4])\n",
    "            print(f\"  DEBUG: Sample weight tops: {df_weights['top'].head(3).tolist()}\")\n",
    "            print(f\"  DEBUG: Sample weight bases: {df_weights['base'].head(3).tolist()}\")\n",
    "        else:\n",
    "            print(f\"  WARNING: Weights file doesn't have expected format, skipping {CORE_NAME}\")\n",
    "            failed_cores.append((CORE_NAME, \"Weights file format incorrect\"))\n",
    "            continue\n",
    "        \n",
    "        # Merge on top and base depths\n",
    "        merged = df_processed.merge(df_weights[['top', 'base', 'Weight (g)']], \n",
    "                                    on=['top', 'base'], how='inner')\n",
    "        \n",
    "        # Add other required columns from weights if present\n",
    "        if 'center' in df_weights.columns:\n",
    "            # Re-merge to get center column\n",
    "            merged = df_processed.merge(df_weights[['top', 'base', 'center', 'Weight (g)']], \n",
    "                                        on=['top', 'base'], how='inner')\n",
    "            merged['Top of interval (cm)'] = merged['top']\n",
    "            merged['Base of interval (cm)'] = merged['base']\n",
    "            merged['Center point of interval'] = merged['center']\n",
    "        \n",
    "        print(f\"  DEBUG: After merge: {len(merged)} rows\")\n",
    "        \n",
    "        if len(merged) == 0:\n",
    "            print(f\"  WARNING: No data after merging, skipping {CORE_NAME}\")\n",
    "            failed_cores.append((CORE_NAME, \"No data after merging weights\"))\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Merged {len(merged)} samples\")\n",
    "        \n",
    "        # Handle missing depths\n",
    "        if missing_choice == 'ask':\n",
    "            has_missing = input(f\"  Does {CORE_NAME} have undetectable radioisotopes? (yes/no): \").strip().lower()\n",
    "            if has_missing == 'yes':\n",
    "                missing_input = input(f\"    Enter depths (comma-separated): \").strip()\n",
    "                missing_depths = [float(x.strip()) for x in missing_input.split(',')]\n",
    "            else:\n",
    "                missing_depths = []\n",
    "        elif missing_choice == 'yes':\n",
    "            missing_input = input(f\"  Enter missing depths for {CORE_NAME} (comma-separated): \").strip()\n",
    "            missing_depths = [float(x.strip()) for x in missing_input.split(',')] if missing_input else []\n",
    "        else:\n",
    "            missing_depths = []\n",
    "        \n",
    "        # Determine year for this core\n",
    "        if default_year_of_core:\n",
    "            # Use global year\n",
    "            year_of_core = default_year_of_core\n",
    "            print(f\"  Using year: {year_of_core}\")\n",
    "        else:\n",
    "            # Use detected year or ask\n",
    "            detected_year = core_years.get(CORE_NAME_RAW)\n",
    "            if detected_year:\n",
    "                year_of_core = detected_year\n",
    "                print(f\"  Using detected year: {year_of_core}\")\n",
    "            else:\n",
    "                year_of_core = int(input(f\"  Enter year for {CORE_NAME}: \"))\n",
    "        \n",
    "        # Calculate age model\n",
    "        print(f\"  Calculating age model...\")\n",
    "        data = calculate_age_model(merged, year_of_core, missing_depths)\n",
    "        \n",
    "        # Save calculated data\n",
    "        calc_csv_path = compose_output_name(\"AgeModelData\", \".csv\", core_folder, SUFFIX)\n",
    "        data.to_csv(calc_csv_path, index=False)\n",
    "        print(f\"  Saved age model data to {calc_csv_path.name}\")\n",
    "        \n",
    "        # Handle depth labeling\n",
    "        if label_choice == 'all':\n",
    "            depths_to_label = data['Center point of interval'].tolist()\n",
    "        elif label_choice == 'ask':\n",
    "            label_input = input(f\"  Label depths for {CORE_NAME}? (all/none/specific): \").strip().lower()\n",
    "            if label_input == 'all':\n",
    "                depths_to_label = data['Center point of interval'].tolist()\n",
    "            elif label_input == 'specific':\n",
    "                depths_input = input(f\"    Enter depths (comma-separated): \").strip()\n",
    "                depths_to_label = [float(x.strip()) for x in depths_input.split(',')]\n",
    "            else:\n",
    "                depths_to_label = []\n",
    "        else:\n",
    "            depths_to_label = []\n",
    "        \n",
    "        # Create plots\n",
    "        print(f\"  Creating plots...\")\n",
    "        save_location = core_folder / \"outputs\"\n",
    "        save_location.mkdir(exist_ok=True)\n",
    "        \n",
    "        plot_uncorrected_activity(data, CORE_NAME, missing_depths, save_location, META)\n",
    "        plot_age_model(data, CORE_NAME, missing_depths, depths_to_label, save_location, META)\n",
    "        \n",
    "        print(f\"  ✓ Successfully processed {CORE_NAME}\")\n",
    "        results.append((CORE_NAME, \"Success\", str(save_location)))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ ERROR processing {core_folder.name}:\")\n",
    "        print(f\"    {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        failed_cores.append((core_folder.name, str(e)))\n",
    "        continue\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"BATCH PROCESSING COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nSuccessfully processed: {len(results)} cores\")\n",
    "for core_name, status, location in results:\n",
    "    print(f\"  ✓ {core_name} -> {location}\")\n",
    "\n",
    "if failed_cores:\n",
    "    print(f\"\\nFailed to process: {len(failed_cores)} cores\")\n",
    "    for core_name, error in failed_cores:\n",
    "        print(f\"  ✗ {core_name}: {error}\")\n",
    "else:\n",
    "    print(f\"\\nAll cores processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completion",
   "metadata": {},
   "source": [
    "# Batch Processing Complete!\n",
    "\n",
    "All cores have been processed. Check the summary above for any errors.\n",
    "\n",
    "#### When you've finished, go to Cell > All Output > Clear to be ready for the next batch run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pb210)",
   "language": "python",
   "name": "pb210"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
